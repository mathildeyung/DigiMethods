{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: APIs and Functions II \n",
    "\n",
    "## 4.1 Using the Twitter API to collect data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1.1** Find the Twitter account of the University of Copenhagen's Faculty of Social Science _by hand_ and get their Twitter account information using `tweepy` functionality. Remember that you just started a new Jupyter Notebook, so you will have to load the necessary modules and set up your authentication with the Twitter API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing the tweepy module\n",
    "\n",
    "import sys\n",
    "! conda install --yes --prefix {sys.prefix} -c conda-forge tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.0\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "print(tweepy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up my authetication with the API\n",
    "\n",
    "CONSUMER_KEY = \"FULYEYV7jl8leJSPd1s1w3cDT\"\n",
    "CONSUMER_SECRET = \"d2Cch1IQ6j14rexgL95vpSbVZdMNmpS4mJEyrsb5HvfiDwi5Up\"\n",
    "\n",
    "ACCESS_TOKEN = \"1037999668343517184-5TV8TkeV13lMZHzUju1NXP0ArcMw7w\"\n",
    "ACCESS_TOKEN_SECRET = \"BXXbmNSsr2UyPTE4At0f0zN1kzeCsxzLeDILDLtneQ5lA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER 4.1.1\n",
    "\n",
    "kusamf_timeline = api.get_user ('KuSamf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1.2** When was this account created? Try to use the `str` and `print` commands to respond with a complete sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The account was created at 2015-12-16 10:21:24\n"
     ]
    }
   ],
   "source": [
    "# ANSWER 4.1.2\n",
    "\n",
    "print('The account was created at ' + str(kusamf_timeline.created_at))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1.3** Can you find out 1) where this account is located, 2) how many people are following the account, and 3) how many accounts the account is following?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capital Region, Denmark\n",
      "995\n",
      "239\n"
     ]
    }
   ],
   "source": [
    "# ANSWER 4.1.3\n",
    "\n",
    "# 1) location\n",
    "\n",
    "print(kusamf_timeline.location)\n",
    "\n",
    "# 2) followers of the account\n",
    "\n",
    "print(kusamf_timeline.followers_count)\n",
    "\n",
    "# 3) number of accounts KuSamf is following (i.e. 'friends' in Twitter language)\n",
    "\n",
    "print (kusamf_timeline.friends_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1.4** Next, get the timeline for this user \"mfroman\". What happens? Can you explain why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TweepError",
     "evalue": "Not authorized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTweepError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-2d35c93ffa21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ANSWER 4.1.4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmfroman_timeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_timeline\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'mfroman'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tweepy/binder.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tweepy/binder.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mRateLimitError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTweepError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_error_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;31m# Parse the response payload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTweepError\u001b[0m: Not authorized."
     ]
    }
   ],
   "source": [
    "# ANSWER 4.1.4 \n",
    "\n",
    "mfroman_timeline = api.user_timeline ('mfroman')\n",
    "\n",
    "# Most likely the user has 'protected tweets', which means that the API cannot interact with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1.5** Now, get the timeline for our example account \"vicariousveblen\". Some of the tweets were posted automatically, i.e. using a Python script. Can you tell from the metadata which? How?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-18 16:49:23\n",
      "2020-02-18 16:47:23\n",
      "2020-02-18 16:45:22\n",
      "2020-02-18 16:16:46\n"
     ]
    }
   ],
   "source": [
    "# ANSWER 4.1.5\n",
    "\n",
    "vv_timeline = api.user_timeline ('vicariousveblen')\n",
    "\n",
    "for tweet in vv_timeline:\n",
    "    print(tweet.created_at)\n",
    "\n",
    "# usually if a bot has posted the tweets you will be able to tell by the timestamps which will sometimes be\n",
    "# to regular i.e. a couple of minutes apart. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Writing and using our own functions to process the Twitter data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2.1** Collect the timeline for this account \"CPH_SODAS\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER 4.2.1 \n",
    "\n",
    "sodas_timeline = api.user_timeline ('CPH_SODAS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2.2** Write a function that you can use to summarize the tweets in the timelineâ€“feel free to look at the code examples we used earlier today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER 4.2.2 \n",
    "\n",
    "def sodas_gist (user_timeline):\n",
    "    \n",
    "    # set up the containers you will need for the loop, e.g. word frequency, lists etc.\n",
    "    word_freq = {}\n",
    "    word_list = []\n",
    "    gist = []\n",
    "    \n",
    "    #Looping through and splitting the tweets into a list of words then combining using .extend\n",
    "    for tweet in (sodas_timeline):\n",
    "        tweet_words = tweet.text.split()\n",
    "        word_list.extend(tweet_words)\n",
    "    \n",
    "    # Adding each word and count the word frequence dictionary \n",
    "    for word in word_list:\n",
    "        if word not in word_freq:\n",
    "            word_freq[word] = word_list.count(word)\n",
    "\n",
    "    #Looping through the dictionary and adding each key pair to the list \n",
    "    \n",
    "    for key in word_freq:\n",
    "        gist.append((word_freq[key], key))\n",
    "    \n",
    "    #Then sorting and reversing the list \n",
    "    gist.sort()\n",
    "    gist.reverse()\n",
    "    \n",
    "    #Finally return \n",
    "    \n",
    "    return gist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11, 'on'),\n",
       " (10, 'the'),\n",
       " (9, 'and'),\n",
       " (9, 'RT'),\n",
       " (6, 'of'),\n",
       " (5, '@distractdenmark:'),\n",
       " (5, '#machineanthropology'),\n",
       " (4, 'workshop'),\n",
       " (4, 'to'),\n",
       " (4, 'out'),\n",
       " (4, 'in'),\n",
       " (3, 'this'),\n",
       " (3, 'social'),\n",
       " (3, 'series'),\n",
       " (3, 'how'),\n",
       " (3, 'for'),\n",
       " (3, 'about'),\n",
       " (3, 'a'),\n",
       " (3, 'Morten'),\n",
       " (3, 'Axel'),\n",
       " (3, '@suneman'),\n",
       " (3, '&amp;'),\n",
       " (2, 'with'),\n",
       " (2, 'theâ€¦'),\n",
       " (2, 'talk'),\n",
       " (2, 'stage'),\n",
       " (2, 'science'),\n",
       " (2, 'piece'),\n",
       " (2, 'our'),\n",
       " (2, 'new'),\n",
       " (2, 'media'),\n",
       " (2, 'have'),\n",
       " (2, 'from'),\n",
       " (2, 'first'),\n",
       " (2, 'commenting'),\n",
       " (2, 'been'),\n",
       " (2, 'an'),\n",
       " (2, 'What'),\n",
       " (2, 'The'),\n",
       " (2, 'Pedersen'),\n",
       " (2, 'Machine'),\n",
       " (2, 'MSc'),\n",
       " (2, 'Join'),\n",
       " (2, 'In'),\n",
       " (2, 'Check'),\n",
       " (2, '@andbjn:'),\n",
       " (2, '@CPH_SODAS'),\n",
       " (1, \"ðŸ“²'Politikere\"),\n",
       " (1, 'you'),\n",
       " (1, 'will'),\n",
       " (1, 'widely'),\n",
       " (1, 'which'),\n",
       " (1, 'where'),\n",
       " (1, 'well-off'),\n",
       " (1, 'we'),\n",
       " (1, 'want'),\n",
       " (1, 'visited'),\n",
       " (1, 'very'),\n",
       " (1, 'verdens'),\n",
       " (1, 'various'),\n",
       " (1, 'using'),\n",
       " (1, 'use'),\n",
       " (1, 'us'),\n",
       " (1, 'two'),\n",
       " (1, 'transfer'),\n",
       " (1, 'tools?'),\n",
       " (1, 'through'),\n",
       " (1, 'thing'),\n",
       " (1, 'their'),\n",
       " (1, 'that'),\n",
       " (1, 'taste?'),\n",
       " (1, 'talks'),\n",
       " (1, 'surrounding'),\n",
       " (1, 'study'),\n",
       " (1, 'spring'),\n",
       " (1, 'speakers'),\n",
       " (1, 'socialâ€¦'),\n",
       " (1, 'simple'),\n",
       " (1, 'shape'),\n",
       " (1, 'second'),\n",
       " (1, 'scientist'),\n",
       " (1, 'school'),\n",
       " (1, 'revolves'),\n",
       " (1, 'research.'),\n",
       " (1, 'redrawing'),\n",
       " (1, 'reactions'),\n",
       " (1, 'questioâ€¦'),\n",
       " (1, 'question'),\n",
       " (1, 'pÃ¥'),\n",
       " (1, 'project'),\n",
       " (1, 'progâ€¦'),\n",
       " (1, 'program'),\n",
       " (1, 'professor'),\n",
       " (1, 'presentations'),\n",
       " (1, 'pres'),\n",
       " (1, 'predicting'),\n",
       " (1, 'perspectives'),\n",
       " (1, 'people'),\n",
       " (1, 'participated'),\n",
       " (1, 'others'),\n",
       " (1, 'opinion'),\n",
       " (1, 'og'),\n",
       " (1, 'next'),\n",
       " (1, 'news'),\n",
       " (1, 'neighborhâ€¦'),\n",
       " (1, 'mobil'),\n",
       " (1, 'mixing'),\n",
       " (1, 'miss'),\n",
       " (1, 'might'),\n",
       " (1, 'methâ€¦'),\n",
       " (1, 'methods.'),\n",
       " (1, 'mechanisms'),\n",
       " (1, 'matters'),\n",
       " (1, 'lecture'),\n",
       " (1, 'kids'),\n",
       " (1, 'just'),\n",
       " (1, 'joint'),\n",
       " (1, 'is'),\n",
       " (1, 'invited'),\n",
       " (1, 'interesting'),\n",
       " (1, 'influence'),\n",
       " (1, 'inequalities'),\n",
       " (1, 'i'),\n",
       " (1, 'https://t.co/uE9OgPujF5'),\n",
       " (1, 'https://t.co/sMZJ5l6ymG'),\n",
       " (1, 'https://t.co/hi2vClmf3e'),\n",
       " (1, 'https://t.co/b54dD3HmjC'),\n",
       " (1, 'https://t.co/YvqlQOqFsR'),\n",
       " (1, 'https://t.co/XvslIriVf4'),\n",
       " (1, 'https://t.co/VE1Q1BQsrW'),\n",
       " (1, 'https://t.co/KaoRrJUG0e'),\n",
       " (1, 'https://t.co/EKO5wosjo1'),\n",
       " (1, 'https://t.co/Arg6Mbg8ms'),\n",
       " (1, 'https://t.co/72RDrSqXâ€¦'),\n",
       " (1, 'https://t.co/62KsL3j8cY'),\n",
       " (1, 'https://t.co/5Emhm5xdNx'),\n",
       " (1, 'https://t.co/2FGpnRtu6Y'),\n",
       " (1, 'host'),\n",
       " (1, 'hele'),\n",
       " (1, 'has'),\n",
       " (1, 'grant!'),\n",
       " (1, 'front'),\n",
       " (1, 'forhandlingsrummet'),\n",
       " (1, 'forhandler'),\n",
       " (1, 'foran'),\n",
       " (1, 'fellow'),\n",
       " (1, 'episode'),\n",
       " (1, 'emojis,'),\n",
       " (1, 'distinction'),\n",
       " (1, 'diplomats'),\n",
       " (1, 'developments'),\n",
       " (1, 'decrease'),\n",
       " (1, 'dealing'),\n",
       " (1, 'de'),\n",
       " (1, 'dayâ€™s'),\n",
       " (1, 'days'),\n",
       " (1, 'data'),\n",
       " (1, 'coâ€¦'),\n",
       " (1, 'contagions.'),\n",
       " (1, 'computational'),\n",
       " (1, 'complex'),\n",
       " (1, 'combining'),\n",
       " (1, 'colleagueâ€¦'),\n",
       " (1, 'colleagues.'),\n",
       " (1, 'co-organized'),\n",
       " (1, 'centered'),\n",
       " (1, 'bÃ¥de'),\n",
       " (1, 'by'),\n",
       " (1, 'boundaries'),\n",
       " (1, 'bots'),\n",
       " (1, 'between'),\n",
       " (1, 'before'),\n",
       " (1, 'befolkning'),\n",
       " (1, 'be?'),\n",
       " (1, 'back'),\n",
       " (1, 'awarded'),\n",
       " (1, 'attendance'),\n",
       " (1, 'at'),\n",
       " (1, 'aspects'),\n",
       " (1, 'as'),\n",
       " (1, 'arounâ€¦'),\n",
       " (1, 'around'),\n",
       " (1, 'areâ€¦'),\n",
       " (1, 'affect'),\n",
       " (1, 'address'),\n",
       " (1, 'Willadsen'),\n",
       " (1, 'Vincent'),\n",
       " (1, 'UCPH'),\n",
       " (1, 'Turns'),\n",
       " (1, 'This'),\n",
       " (1, 'Thick'),\n",
       " (1, 'Testing'),\n",
       " (1, 'Sune'),\n",
       " (1, 'Spring'),\n",
       " (1, 'Social'),\n",
       " (1, 'Series'),\n",
       " (1, 'Say'),\n",
       " (1, 'Sapienza'),\n",
       " (1, 'SODAS'),\n",
       " (1, 'Râ€¦'),\n",
       " (1, 'Rebecca'),\n",
       " (1, 'Rayâ€¦'),\n",
       " (1, 'Prof.'),\n",
       " (1, 'Phillip'),\n",
       " (1, 'PhD'),\n",
       " (1, 'Peter'),\n",
       " (1, 'Pedersen,'),\n",
       " (1, 'Passionate'),\n",
       " (1, 'Nicolajsen'),\n",
       " (1, 'News'),\n",
       " (1, 'Networks'),\n",
       " (1, 'Nature'),\n",
       " (1, 'Monday.'),\n",
       " (1, 'Monday'),\n",
       " (1, 'Lehmann'),\n",
       " (1, 'Kristin'),\n",
       " (1, 'Kelton'),\n",
       " (1, 'Jâ€¦'),\n",
       " (1, 'Information'),\n",
       " (1, 'Hendricks'),\n",
       " (1, 'Helene'),\n",
       " (1, 'Halkier'),\n",
       " (1, 'For'),\n",
       " (1, \"Don't\"),\n",
       " (1, 'Discussion'),\n",
       " (1, 'December'),\n",
       " (1, 'Data+'),\n",
       " (1, 'Data'),\n",
       " (1, 'DISTRACT'),\n",
       " (1, 'Copenhagen.â€¦'),\n",
       " (1, 'Chinese'),\n",
       " (1, 'Can'),\n",
       " (1, 'Bubbles'),\n",
       " (1, 'Brooker'),\n",
       " (1, 'Anthropology'),\n",
       " (1, 'Anna'),\n",
       " (1, 'Anabel'),\n",
       " (1, 'Adler-Nissen'),\n",
       " (1, 'AI,'),\n",
       " (1, 'A'),\n",
       " (1, \"@suneman's\"),\n",
       " (1, '@naturep'),\n",
       " (1, '@fmerhout'),\n",
       " (1, '@daviddlassen,'),\n",
       " (1, '@daviddlassen'),\n",
       " (1, '@TANTlab:'),\n",
       " (1, '@RebAdlerNissen,'),\n",
       " (1, '@RebAdlerNissen'),\n",
       " (1, \"@It_vest's\"),\n",
       " (1, '@Golovchenko_Yev'),\n",
       " (1, '@DIPâ€¦'),\n",
       " (1, '@Carlsbergfondet:'),\n",
       " (1, '@CPH_SODAS.'),\n",
       " (1, '@AndersKMunk'),\n",
       " (1, '(1/7)'),\n",
       " (1, \"'thick'â€¦\"),\n",
       " (1, '#thickmachine'),\n",
       " (1, '#segregation?')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sodas_gist(sodas_timeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2.3** Apply the function to the timeline data you collected. Without looking it up, what would you say this account tweets about?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Follow Your Interests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3.1** Identify three Twitter accounts _or_ key words of interest to you. Use the functionality we learned today to look at their history of the accounts, who tweets about your keywords, what do your accounts tweet about etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
